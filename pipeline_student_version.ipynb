{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6z7ncXirnv7"
   },
   "source": [
    "# Building an ETL Pipeline\n",
    "\n",
    "As the second part of the predict for Gather, you will need to build a pipeline of functions in python which does the following:\n",
    "\n",
    "1. Function to connect to twitter and scrapes \"Eskom_SA\" tweets.\n",
    "<br>\n",
    "<br>\n",
    "2. Cleans/Processes the tweets from the scraped tweets which will create a dataframe with two new columns using the following functions: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a) Hashtag Remover from Analyse Functions\n",
    "<br>\n",
    "<br>\n",
    "3. Functions which connects to your SQL database and uploads the tweets into the table you store the tweets in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtYowqI_RiBL"
   },
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For numerical computation\n",
    "import json\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EykRIHe8ykYS"
   },
   "source": [
    "# Consumer and Access details\n",
    "\n",
    "Fill in your Consumer and Access details you should have recieved when applying for a Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lquylmvOnFvt"
   },
   "outputs": [],
   "source": [
    "# Consumer:\n",
    "MY_CONSUMER_KEY    = 'hkeVlDanGNTN8DRQF8HqlTWBa'\n",
    "MY_CONSUMER_SECRET = 'MQKqkhGXl4ukGUcQCSHxd7GfHOIjMvgABHJ0N2TdBV1nochloi'\n",
    "\n",
    "# Access:\n",
    "MY_ACCESS_TOKEN  = '1399297879-NLwurAjgf7grsIx3AqLK3z0HaMKOpqWEjvZj7PV'\n",
    "MY_ACCESS_SECRET = 'qRuUzew94mze9sY4HpK4SS6vCVwZJW6ZjHOS2o5HjjGph'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5nbkmC9vk8F"
   },
   "source": [
    "# Function 1:\n",
    "\n",
    "Write a function which:\n",
    "- Scrapes _\"Eskom_SA\"_ tweets from Twitter. \n",
    "\n",
    "Function Specifications:\n",
    "- The function should return a dataframe with the scraped tweets with just the \"_Tweets_\" and \"_Date_\". \n",
    "- Will take in the ```consumer key,  consumer secret code, access token``` and ```access secret code```.\n",
    "\n",
    "NOTE:\n",
    "The dataframe should have the same column names as those in your SQL Database table where you store the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eF6Vnzl3RiBX"
   },
   "outputs": [],
   "source": [
    "def twitter_df(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET ):\n",
    "    \"\"\"Returns a dataframe with scraped Eskom_SA tweets, date of the tweet and location from Twitter\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    CONSUMER_KEY    = 'Twitter API Key'\n",
    "    \n",
    "    CONSUMER_SECRET = 'Twitter API Secret Key'\n",
    "\n",
    "    ACCESS_TOKEN  = 'Twitter Access Token'\n",
    "    \n",
    "    ACCESS_SECRET = 'Twitter Access Token Secret'\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    \n",
    "    >>> twitter_df('API_key', 'API_secret_key', 'access_token', 'access_secret_token' )\n",
    "    \n",
    "    tweet                                |                  date |\n",
    "    -------------------------------------|-----------------------|---------------\n",
    "    Some tweet @someone about #something |   2020-03-11 11:37:49 |\n",
    "    \"\"\"\n",
    "\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    \n",
    "    api = tweepy.API(auth, timeout=1000)\n",
    "    \n",
    "    tweets = []\n",
    "    dates = []\n",
    "    location = []\n",
    "    result = pd.DataFrame()\n",
    "    for tweet in api.search(q=\"@Eskom_SA -filter:retweets\", lang=\"en\", rpp=100, count=40):\n",
    "        tweets = tweets + [f\"{tweet.text}\"]\n",
    "        dates = dates + [f\"{tweet.created_at}\"]\n",
    "        location = location + [f\"{tweet.user.location}\"]\n",
    "    result['Tweets'] = tweets\n",
    "    result['Date'] = dates\n",
    "    result['Location'] = location\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = twitter_df(MY_CONSUMER_KEY, MY_CONSUMER_SECRET, MY_ACCESS_TOKEN, MY_ACCESS_SECRET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='EDSA-PGLBGKO\\SQLEXPRESS',\n",
    "                      database='gather_eskom',\n",
    "                      uid='sa',\n",
    "                      pwd='edsa@2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyodbc_twitter(connection, df, twitter_table):\n",
    "    \"\"\"Extracts a dataframe containing tweets, connects and updates the data in your local SQL database\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    connection: SQL connection settings\n",
    "\n",
    "    df: DataFrame of tweets with their timestamp and location \n",
    "\n",
    "    twitter_table: An already existing twitter SQL database \n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='your_server_name',\n",
    "                      database='your_database_name', \n",
    "                      uid='your_user_name',\n",
    "                      pwd='your_password')\n",
    "    \n",
    "    >>> df = \n",
    "    \n",
    "    \n",
    "    >>> sql_df = pd.read_sql_query('SELECT * FROM twitter_table')\n",
    "    tweets   date   location\n",
    "    \n",
    "    >>> pyodbc_twitter(connection, df, twitter_table)\n",
    "    tweets           date           location\n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    for i in range(len(df.index)):\n",
    "        \n",
    "        tweet_text = df['Tweets'][i]\n",
    "        tweet_text = tweet_text.replace(\"'\",\"\")\n",
    "        tweet_date = df['Date'][i]\n",
    "        tweet_location = df['Location'][i]\n",
    "        \n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {twitter_table}\n",
    "            VALUES ('{tweet_text}', '{tweet_date}', '{tweet_location}')\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "    conn.commit()\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyodbc_twitter(conn, tweets_df, 'eskom_tweets_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='EDSA-PGLBGKO\\SQLEXPRESS',\n",
    "                      database='gather_eskom',\n",
    "                      uid='sa',\n",
    "                      pwd='edsa@2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = pd.read_sql_query('SELECT * FROM eskom_tweets_raw', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Eskom_SA @SABCNewsOnline @SABCRadio @IOL @ewn...</td>\n",
       "      <td>2020-03-11 04:05:12</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Eskom_SA Than youll go crying to the high cou...</td>\n",
       "      <td>2020-03-11 04:04:49</td>\n",
       "      <td>Far South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Eskom_SA And use a moon/sun to cook it??</td>\n",
       "      <td>2020-03-11 04:02:54</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@M_Jay94 @AntonEberhard @Eskom_SA ESKOM manage...</td>\n",
       "      <td>2020-03-11 04:02:02</td>\n",
       "      <td>Johannesburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nke_Le @Eskom_SA @barrybateman @SABCNewsOnlin...</td>\n",
       "      <td>2020-03-11 04:01:34</td>\n",
       "      <td>Pretoria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets                 date  \\\n",
       "0  @Eskom_SA @SABCNewsOnline @SABCRadio @IOL @ewn...  2020-03-11 04:05:12   \n",
       "1  @Eskom_SA Than youll go crying to the high cou...  2020-03-11 04:04:49   \n",
       "2          @Eskom_SA And use a moon/sun to cook it??  2020-03-11 04:02:54   \n",
       "3  @M_Jay94 @AntonEberhard @Eskom_SA ESKOM manage...  2020-03-11 04:02:02   \n",
       "4  @nke_Le @Eskom_SA @barrybateman @SABCNewsOnlin...  2020-03-11 04:01:34   \n",
       "\n",
       "                     location  \n",
       "0                South Africa  \n",
       "1                   Far South  \n",
       "2  Johannesburg, South Africa  \n",
       "3                Johannesburg  \n",
       "4                    Pretoria  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkUQUNKzpUN2"
   },
   "source": [
    "# Function 2: Removing hashtags and the municipalities\n",
    "\n",
    "Write a function which:\n",
    "- Uses the function you wrote in the Analyse section to extract the hashtags and municipalities into it's own column in a new data frame. \n",
    "\n",
    "Function Specifications:\n",
    "- The function should take in the pandas dataframe you created in Function 1 and return a new pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOuThS2kRiBf"
   },
   "outputs": [],
   "source": [
    "def extract_municipality_hashtags(df):\n",
    "    \n",
    "    \"\"\"Returns a modified dataframe with two new columns appended, \"municipality\" and \"hashtags\". Information is extracted from\n",
    "    twitter data that includes the municipality and the list of hashtags referred to in each tweet, respectively.\n",
    "    Input must contain a column named \"Tweets\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_new: modified dataframe \n",
    "    \"\"\"\n",
    "    \n",
    "    mun_dict = {'@CityofCTAlerts' : 'Cape Town',\n",
    "                '@CityPowerJhb' : 'Johannesburg',\n",
    "                '@eThekwiniM' : 'eThekwini' ,\n",
    "                '@EMMInfo' : 'Ekurhuleni',\n",
    "                '@centlecutility' : 'Mangaung',\n",
    "                '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "                '@CityTshwane' : 'Tshwane'}\n",
    "    \n",
    "    if type(df) == type(pd.DataFrame()):\n",
    "        municipality = []\n",
    "        data = df\n",
    "        for i in data[\"tweets\"]:\n",
    "            data_str = i.replace(\":\", \"\") # Remove \":\" from the end of municipality keys and hashtags\n",
    "            data_str = str.split(data_str) # Splits a sentence/multi-word string by white space into a list\n",
    "            data_muni = [a for a in data_str if a[0] == \"@\"] # Add words containing the hashtag to new list\n",
    "            municipality = municipality + [data_muni]\n",
    "        for j in range(len(municipality)):\n",
    "            municipality[j] = [i.replace(i, mun_dict[i]) for i in municipality[j] if i in mun_dict]\n",
    "        for x in range(len(municipality)):\n",
    "            if municipality[x] == []:\n",
    "                municipality[x] = (np.nan)\n",
    "\n",
    "        df_muni = pd.DataFrame({\"municipality\": municipality})\n",
    "        df = df.join(df_muni)\n",
    "    \n",
    "        data_subset = df\n",
    "        hashtags = []\n",
    "        for j, k in data_subset.iterrows(): # Iterate over pd df\n",
    "            data_subset_str = data_subset.iloc[j,0]\n",
    "            data_subset_str = str.split(data_subset_str) # Splits a sentence/multi-word string by white space into a list\n",
    "            data_subset_hashtags = [a for a in data_subset_str if a[0] == \"#\"] # Add words containing the hashtag to new list\n",
    "            data_subset_hashtags = list(map(lambda b: str.lower(b), data_subset_hashtags)) # Convert all hashtags in list to lower case\n",
    "            if data_subset_hashtags == []:\n",
    "                data_subset_hashtags = (np.nan) # Use () instead of [], resulting nan must not have square brackets in solution\n",
    "            hashtags = hashtags + [data_subset_hashtags]\n",
    "\n",
    "        df = data_subset\n",
    "        df2 = pd.DataFrame({\"hashtags\": hashtags})\n",
    "        df = df.join(df2)\n",
    "        df_new = df\n",
    "    \n",
    "    else:\n",
    "        print(\"Error: input must be a data frame.\")\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets_df = extract_municipality_hashtags(sql_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>municipality</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Eskom_SA @SABCNewsOnline @SABCRadio @IOL @ewn...</td>\n",
       "      <td>2020-03-11 04:05:12</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Eskom_SA Than youll go crying to the high cou...</td>\n",
       "      <td>2020-03-11 04:04:49</td>\n",
       "      <td>Far South</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Eskom_SA And use a moon/sun to cook it??</td>\n",
       "      <td>2020-03-11 04:02:54</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@M_Jay94 @AntonEberhard @Eskom_SA ESKOM manage...</td>\n",
       "      <td>2020-03-11 04:02:02</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nke_Le @Eskom_SA @barrybateman @SABCNewsOnlin...</td>\n",
       "      <td>2020-03-11 04:01:34</td>\n",
       "      <td>Pretoria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets                 date  \\\n",
       "0  @Eskom_SA @SABCNewsOnline @SABCRadio @IOL @ewn...  2020-03-11 04:05:12   \n",
       "1  @Eskom_SA Than youll go crying to the high cou...  2020-03-11 04:04:49   \n",
       "2          @Eskom_SA And use a moon/sun to cook it??  2020-03-11 04:02:54   \n",
       "3  @M_Jay94 @AntonEberhard @Eskom_SA ESKOM manage...  2020-03-11 04:02:02   \n",
       "4  @nke_Le @Eskom_SA @barrybateman @SABCNewsOnlin...  2020-03-11 04:01:34   \n",
       "\n",
       "                     location municipality hashtags  \n",
       "0                South Africa          NaN      NaN  \n",
       "1                   Far South          NaN      NaN  \n",
       "2  Johannesburg, South Africa          NaN      NaN  \n",
       "3                Johannesburg          NaN      NaN  \n",
       "4                    Pretoria          NaN      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9bXQ_k8xOjV"
   },
   "source": [
    "# Function 3: Updating SQL Database with pyODBC\n",
    "\n",
    "Write a function which:\n",
    "- Connects and updates your SQL database. \n",
    "\n",
    "Function Specifications:\n",
    "- The function should take in a pandas dataframe created in Function 2. \n",
    "- Connect to your SQL database.\n",
    "- Update the table you store your tweets in.\n",
    "- Not return any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqdiXb5JRiBo"
   },
   "outputs": [],
   "source": [
    "def pyodbc_twitter(connection, df, twitter_table):\n",
    "    \"\"\"Extracts a dataframe of tweets and connects and updates the data in your local SQL database\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    connection: SQL connection settings\n",
    "\n",
    "    df: DataFrame of tweets with their timestamp\n",
    "\n",
    "    twitter_table: An already existing twitter SQL database \n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='your_server_name',\n",
    "                      database='your_database_name', \n",
    "                      trusted_connection='tcon',\n",
    "                      user='your_user_name',\n",
    "                      autocommit=True)\n",
    "    \n",
    "    >>> df = \n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    for i in range(len(df.index)):\n",
    "        \n",
    "        tweet_text = df['tweets'][i]\n",
    "        tweet_text = tweet_text.replace(\"'\",\"\")\n",
    "        \n",
    "        tweet_date = df['date'][i]\n",
    "        tweet_municipality = df['municipality']\n",
    "        tweet_hashtags = df['hashtags'] \n",
    "        tweet_location = df['location']\n",
    "        print(f\"\"\"\n",
    "            INSERT INTO {twitter_table}\n",
    "            VALUES (\n",
    "                '{tweet_text}',\n",
    "                '{tweet_date}',\n",
    "                '{tweet_municipality}',\n",
    "                '{tweet_hashtags}',\n",
    "                '{tweet_location}'\n",
    "            )\n",
    "            \"\"\")\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {twitter_table}\n",
    "            VALUES ('{tweet_text}','{tweet_date}','{tweet_municipality}','{tweet_hashtags}','{tweet_location}')\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "    conn.commit()\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            INSERT INTO eskom_tweets_processed\n",
      "            VALUES (\n",
      "                '@Eskom_SA @SABCNewsOnline @SABCRadio @IOL @ewnupdates @eNCA @TimesLIVE @News24 @Fin24 @Moneyweb @TheSAnews You lostâ€¦ https://t.co/rMILKrHNmi',\n",
      "                '2020-03-11 04:05:12',\n",
      "                '0                NaN\n",
      "1                NaN\n",
      "2                NaN\n",
      "3                NaN\n",
      "4                NaN\n",
      "5                NaN\n",
      "6                NaN\n",
      "7                NaN\n",
      "8                NaN\n",
      "9                NaN\n",
      "10               NaN\n",
      "11               NaN\n",
      "12               NaN\n",
      "13               NaN\n",
      "14               NaN\n",
      "15               NaN\n",
      "16               NaN\n",
      "17               NaN\n",
      "18               NaN\n",
      "19               NaN\n",
      "20               NaN\n",
      "21               NaN\n",
      "22               NaN\n",
      "23    [Johannesburg]\n",
      "24               NaN\n",
      "25               NaN\n",
      "26    [Johannesburg]\n",
      "27               NaN\n",
      "28    [Johannesburg]\n",
      "29         [Tshwane]\n",
      "30    [Johannesburg]\n",
      "31               NaN\n",
      "32    [Johannesburg]\n",
      "33               NaN\n",
      "34    [Johannesburg]\n",
      "35               NaN\n",
      "36    [Johannesburg]\n",
      "37    [Johannesburg]\n",
      "38    [Johannesburg]\n",
      "39    [Johannesburg]\n",
      "Name: municipality, dtype: object',\n",
      "                '0                            NaN\n",
      "1                            NaN\n",
      "2                            NaN\n",
      "3                            NaN\n",
      "4                            NaN\n",
      "5                            NaN\n",
      "6                            NaN\n",
      "7                            NaN\n",
      "8                            NaN\n",
      "9                            NaN\n",
      "10                           NaN\n",
      "11                           NaN\n",
      "12    [#poweralert, #poweralert]\n",
      "13                           NaN\n",
      "14                           NaN\n",
      "15                           NaN\n",
      "16                           NaN\n",
      "17                           NaN\n",
      "18                           NaN\n",
      "19                           NaN\n",
      "20                           NaN\n",
      "21                           NaN\n",
      "22                           NaN\n",
      "23                           NaN\n",
      "24                           NaN\n",
      "25                           NaN\n",
      "26                           NaN\n",
      "27                           NaN\n",
      "28                           NaN\n",
      "29                [#eskomsepush]\n",
      "30                           NaN\n",
      "31                           NaN\n",
      "32                           NaN\n",
      "33                           NaN\n",
      "34                           NaN\n",
      "35                           NaN\n",
      "36                           NaN\n",
      "37                           NaN\n",
      "38                           NaN\n",
      "39                           NaN\n",
      "Name: hashtags, dtype: object',\n",
      "                '0                      South Africa\n",
      "1                         Far South\n",
      "2        Johannesburg, South Africa\n",
      "3                      Johannesburg\n",
      "4                          Pretoria\n",
      "5        Johannesburg, South Africa\n",
      "6        Johannesburg, South Africa\n",
      "7         ??cape town, south africa\n",
      "8                      Johannesburg\n",
      "9           Cape Town, South Africa\n",
      "10                                 \n",
      "11                                 \n",
      "12        Krugersdorp, South Africa\n",
      "13                        Centurion\n",
      "14                                 \n",
      "15                                 \n",
      "16                   Here and there\n",
      "17         Soshanguve, South Africa\n",
      "18                                 \n",
      "19                        Cape Town\n",
      "20          Centurion, South Africa\n",
      "21    Proudly African,South African\n",
      "22                  Pitermaritzburg\n",
      "23                                 \n",
      "24       Johannesburg, South Africa\n",
      "25                        Centurion\n",
      "26                                 \n",
      "27       Johannesburg, South Africa\n",
      "28                                 \n",
      "29          Centurion, South Africa\n",
      "30       Johannesburg, South Africa\n",
      "31                           Joburg\n",
      "32      Johannesburg , South Africa\n",
      "33       Johannesburg, South Africa\n",
      "34       Johannesburg, South Africa\n",
      "35                                 \n",
      "36       Johannesburg, South Africa\n",
      "37                                 \n",
      "38                                 \n",
      "39                     South Africa\n",
      "Name: location, dtype: object'\n",
      "            )\n",
      "            \n"
     ]
    },
    {
     "ename": "DataError",
     "evalue": "('22001', '[22001] [Microsoft][ODBC SQL Server Driver][SQL Server]String or binary data would be truncated. (8152) (SQLExecDirectW); [22001] [Microsoft][ODBC SQL Server Driver][SQL Server]The statement has been terminated. (3621)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-39b0675ab479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpyodbc_twitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessed_tweets_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eskom_tweets_processed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-0bafa61a5590>\u001b[0m in \u001b[0;36mpyodbc_twitter\u001b[1;34m(connection, df, twitter_table)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mINSERT\u001b[0m \u001b[0mINTO\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtwitter_table\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mVALUES\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'{tweet_text}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{tweet_date}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{tweet_municipality}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{tweet_hashtags}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{tweet_location}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \"\"\"\n\u001b[0m\u001b[0;32m     51\u001b[0m         )\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDataError\u001b[0m: ('22001', '[22001] [Microsoft][ODBC SQL Server Driver][SQL Server]String or binary data would be truncated. (8152) (SQLExecDirectW); [22001] [Microsoft][ODBC SQL Server Driver][SQL Server]The statement has been terminated. (3621)')"
     ]
    }
   ],
   "source": [
    "pyodbc_twitter(conn, processed_tweets_df, 'eskom_tweets_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_student_version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
