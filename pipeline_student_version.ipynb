{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6z7ncXirnv7"
   },
   "source": [
    "# Building an ETL Pipeline\n",
    "\n",
    "As the second part of the predict for Gather, you will need to build a pipeline of functions in python which does the following:\n",
    "\n",
    "1. Function to connect to twitter and scrapes \"Eskom_SA\" tweets.\n",
    "<br>\n",
    "<br>\n",
    "2. Cleans/Processes the tweets from the scraped tweets which will create a dataframe with two new columns using the following functions: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a) Hashtag Remover from Analyse Functions\n",
    "<br>\n",
    "<br>\n",
    "3. Functions which connects to your SQL database and uploads the tweets into the table you store the tweets in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtYowqI_RiBL"
   },
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For numerical computation\n",
    "import json\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EykRIHe8ykYS"
   },
   "source": [
    "# Consumer and Access details\n",
    "\n",
    "Fill in your Consumer and Access details you should have recieved when applying for a Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lquylmvOnFvt"
   },
   "outputs": [],
   "source": [
    "# Consumer:\n",
    "MY_CONSUMER_KEY    = ''\n",
    "MY_CONSUMER_SECRET = ''\n",
    "\n",
    "# Access:\n",
    "MY_ACCESS_TOKEN  = ''\n",
    "MY_ACCESS_SECRET = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01RMZH30RiBU"
   },
   "outputs": [],
   "source": [
    "# API's setup:\n",
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with access and consumer keys from Twitter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth, timeout=1000)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5nbkmC9vk8F"
   },
   "source": [
    "# Function 1:\n",
    "\n",
    "Write a function which:\n",
    "- Scrapes _\"Eskom_SA\"_ tweets from Twitter. \n",
    "\n",
    "Function Specifications:\n",
    "- The function should return a dataframe with the scraped tweets with just the \"_Tweets_\" and \"_Date_\". \n",
    "- Will take in the ```consumer key,  consumer secret code, access token``` and ```access secret code```.\n",
    "\n",
    "NOTE:\n",
    "The dataframe should have the same column names as those in your SQL Database table where you store the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eF6Vnzl3RiBX"
   },
   "outputs": [],
   "source": [
    "def twitter_df(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET ):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    \n",
    "    api = tweepy.API(auth, timeout=1000)\n",
    "    \n",
    "    tweets = []\n",
    "    dates = []\n",
    "    location = []\n",
    "    result = pd.DataFrame()\n",
    "    for tweet in api.search(q=\"@Eskom_SA -filter:retweets\", lang=\"en\", rpp=100, count=40):\n",
    "        tweets = tweets + [f\"{tweet.text}\"]\n",
    "        dates = dates + [f\"{tweet.created_at}\"]\n",
    "        location = location + [f\"{tweet.user.location}\"]\n",
    "    result['Tweets'] = tweets\n",
    "    result['Date'] = dates\n",
    "    result['Location'] = location\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = twitter_df(MY_CONSUMER_KEY, MY_CONSUMER_SECRET, MY_ACCESS_TOKEN, MY_ACCESS_SECRET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='EDSA-PGLBGKO\\SQLEXPRESS',\n",
    "                      database='gather_eskom',\n",
    "                      uid='sa',\n",
    "                      pwd='edsa@2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyodbc_twitter(connection, df, twitter_table):\n",
    "    \"\"\"Extracts a dataframe of tweets and connects and updates the data in your local SQL database\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    connection: SQL connection settings\n",
    "\n",
    "    df: DataFrame of tweets with their timestamp\n",
    "\n",
    "    twitter_table: An already existing twitter SQL database \n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='your_server_name',\n",
    "                      database='your_database_name', \n",
    "                      uid='your_user_name',\n",
    "                      pwd='your_password')\n",
    "    \n",
    "    >>> df = \n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    for i in range(len(df.index)):\n",
    "        \n",
    "        tweet_text = df['Tweets'][i]\n",
    "        tweet_text = tweet_text.replace(\"'\",\"\")\n",
    "        tweet_date = df['Date'][i]\n",
    "        tweet_location = df['Location'][i]\n",
    "        \n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {twitter_table}\n",
    "            VALUES ('{tweet_text}', '{tweet_date}', '{tweet_location}')\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "    conn.commit()\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyodbc_twitter(conn, tweets_df, 'eskom_tweets_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Attempt to use a closed connection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8dd0cd799055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m: Attempt to use a closed connection."
     ]
    }
   ],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='EDSA-PGLBGKO\\SQLEXPRESS',\n",
    "                      database='gather_eskom',\n",
    "                      uid='sa',\n",
    "                      pwd='edsa@2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = pd.read_sql_query('SELECT * FROM eskom_tweets_raw', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@Maliqo @koko_matshela @SikonathiM @Eskom_SA Y...</td>\n",
       "      <td>2020-03-10 13:38:18</td>\n",
       "      <td>Midrand, South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@RiDuR @Eskom_SA @SasolSA BTW THE OTHER SASOL ...</td>\n",
       "      <td>2020-03-10 13:37:53</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@SikonathiM @EmfuleniLM @Eskom_SA How did Esko...</td>\n",
       "      <td>2020-03-10 13:37:37</td>\n",
       "      <td>Cape Town, South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Kana how long is Stage 4 Loadshedding? @Sikona...</td>\n",
       "      <td>2020-03-10 13:37:30</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@Eskom_SA @News24 @TimesLIVE @eNCA @IOL @SABCN...</td>\n",
       "      <td>2020-03-10 13:36:56</td>\n",
       "      <td>Port Elizabeth, South Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets                 date  \\\n",
       "0  @Maliqo @koko_matshela @SikonathiM @Eskom_SA Y...  2020-03-10 13:38:18   \n",
       "1  @RiDuR @Eskom_SA @SasolSA BTW THE OTHER SASOL ...  2020-03-10 13:37:53   \n",
       "2  @SikonathiM @EmfuleniLM @Eskom_SA How did Esko...  2020-03-10 13:37:37   \n",
       "3  Kana how long is Stage 4 Loadshedding? @Sikona...  2020-03-10 13:37:30   \n",
       "4  @Eskom_SA @News24 @TimesLIVE @eNCA @IOL @SABCN...  2020-03-10 13:36:56   \n",
       "\n",
       "                           city  \n",
       "0         Midrand, South Africa  \n",
       "1    Johannesburg, South Africa  \n",
       "2       Cape Town, South Africa  \n",
       "3                  South Africa  \n",
       "4  Port Elizabeth, South Africa  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkUQUNKzpUN2"
   },
   "source": [
    "# Function 2: Removing hashtags and the municipalities\n",
    "\n",
    "Write a function which:\n",
    "- Uses the function you wrote in the Analyse section to extract the hashtags and municipalities into it's own column in a new data frame. \n",
    "\n",
    "Function Specifications:\n",
    "- The function should take in the pandas dataframe you created in Function 1 and return a new pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o12Z44mZRiBb"
   },
   "outputs": [],
   "source": [
    "tweets_df = twitter_df(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOuThS2kRiBf"
   },
   "outputs": [],
   "source": [
    "def extract_municipality_hashtags(df):\n",
    "    \n",
    "    \"\"\"Returns a modified dataframe with two new columns appended, \"municipality\" and \"hashtags\". Information is extracted from\n",
    "    twitter data that includes the municipality and the list of hashtags referred to in each tweet, respectively.\n",
    "    Input must contain a column named \"Tweets\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_new: modified dataframe \n",
    "    \"\"\"\n",
    "    \n",
    "    mun_dict = {'@CityofCTAlerts' : 'Cape Town',\n",
    "                '@CityPowerJhb' : 'Johannesburg',\n",
    "                '@eThekwiniM' : 'eThekwini' ,\n",
    "                '@EMMInfo' : 'Ekurhuleni',\n",
    "                '@centlecutility' : 'Mangaung',\n",
    "                '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "                '@CityTshwane' : 'Tshwane'}\n",
    "    \n",
    "    if type(df) == type(pd.DataFrame()):\n",
    "        municipality = []\n",
    "        data = df\n",
    "        for i in data[\"Tweets\"]:\n",
    "            data_str = i.replace(\":\", \"\") # Remove \":\" from the end of municipality keys and hashtags\n",
    "            data_str = str.split(data_str) # Splits a sentence/multi-word string by white space into a list\n",
    "            data_muni = [a for a in data_str if a[0] == \"@\"] # Add words containing the hashtag to new list\n",
    "            municipality = municipality + [data_muni]\n",
    "        for j in range(len(municipality)):\n",
    "            municipality[j] = [i.replace(i, mun_dict[i]) for i in municipality[j] if i in mun_dict]\n",
    "        for x in range(len(municipality)):\n",
    "            if municipality[x] == []:\n",
    "                municipality[x] = (np.nan)\n",
    "\n",
    "        df_muni = pd.DataFrame({\"municipality\": municipality})\n",
    "        df = df.join(df_muni)\n",
    "    \n",
    "        data_subset = df\n",
    "        hashtags = []\n",
    "        for j, k in data_subset.iterrows(): # Iterate over pd df\n",
    "            data_subset_str = data_subset.iloc[j,0]\n",
    "            data_subset_str = str.split(data_subset_str) # Splits a sentence/multi-word string by white space into a list\n",
    "            data_subset_hashtags = [a for a in data_subset_str if a[0] == \"#\"] # Add words containing the hashtag to new list\n",
    "            data_subset_hashtags = list(map(lambda b: str.lower(b), data_subset_hashtags)) # Convert all hashtags in list to lower case\n",
    "            if data_subset_hashtags == []:\n",
    "                data_subset_hashtags = (np.nan) # Use () instead of [], resulting nan must not have square brackets in solution\n",
    "            hashtags = hashtags + [data_subset_hashtags]\n",
    "\n",
    "        df = data_subset\n",
    "        df2 = pd.DataFrame({\"hashtags\": hashtags})\n",
    "        df = df.join(df2)\n",
    "        df_new = df\n",
    "    \n",
    "    else:\n",
    "        print(\"Error: input must be a data frame.\")\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9bXQ_k8xOjV"
   },
   "source": [
    "# Function 3: Updating SQL Database with pyODBC\n",
    "\n",
    "Write a function which:\n",
    "- Connects and updates your SQL database. \n",
    "\n",
    "Function Specifications:\n",
    "- The function should take in a pandas dataframe created in Function 2. \n",
    "- Connect to your SQL database.\n",
    "- Update the table you store your tweets in.\n",
    "- Not return any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqdiXb5JRiBo"
   },
   "outputs": [],
   "source": [
    "def pyodbc_twitter(connection, df, twitter_table):\n",
    "    \"\"\"Extracts a dataframe of tweets and connects and updates the data in your local SQL database\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    connection: SQL connection settings\n",
    "\n",
    "    df: DataFrame of tweets with their timestamp\n",
    "\n",
    "    twitter_table: An already existing twitter SQL database \n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> conn = pyodbc.connect(driver='{SQL Server}',\n",
    "                      host='your_server_name',\n",
    "                      database='your_database_name', \n",
    "                      trusted_connection='tcon',\n",
    "                      user='your_user_name',\n",
    "                      autocommit=True)\n",
    "    \n",
    "    >>> df = \n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    for i in range(len(df.index)):\n",
    "        \n",
    "        tweet_text = df['Tweets'][i]\n",
    "        tweet_text = tweet_text.replace(\"'\",\"\")\n",
    "        tweet_date = df['Date'][i]\n",
    "        \n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            INSERT INTO {twitter_table}\n",
    "            VALUES ('{tweet_text}', '{tweet_date}')\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "    conn.commit()\n",
    "    return None "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_student_version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
